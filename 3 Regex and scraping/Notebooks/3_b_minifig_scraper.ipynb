{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minifig scraper\n",
    "\n",
    "What we did before was nice, but there are libraries that will help us when screenscraping website. A really nice one beautifulsoup. We'll start out by using that one for scraping minifigs.\n",
    "\n",
    "Minifigs are the figurines included in legosets. There are many of them, and some of them have a real personality, while others are more generic. You can find all of them on the [brickset-website](https://brickset.com/browse/minifigs). Note that we won't be downloading them, as that would stress the bandwidth of this free website way to much. The goal therefore is to have a list of URL's, divided by theme.\n",
    "\n",
    "If you want you can still download the image files later on, print them all individually on A4 pages and redecorate your room.\n",
    "\n",
    "But code. First up is including the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests\n",
    "! pip install BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll store the URI in a variable and start downloading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://brickset.com/browse/minifigs\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "print(page.text[:100])\n",
    "print(page.text[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see we have the basic site content now. The actual site is a page with links to all the different themes, and we need all these links to then go and fetch the page behind it. We reach back to trusty old Chrome Inspect to see what part of the website we're interested in:\n",
    "\n",
    "![](images/2022-03-07-21-23-48.png)\n",
    "\n",
    "We can skip everything not in ```\"<div class=\"content\">\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "results = soup.find(\"div\", {\"class\": \"content\"})\n",
    "# print(results.prettify())\n",
    "links = results.find_all(\"a\", href=True)\n",
    "\n",
    "pretty_links = []\n",
    "\n",
    "for link in links:\n",
    "    pretty_links.append( (link.text, link['href']))\n",
    "\n",
    "print(pretty_links[:5])\n",
    "base_url = \"https://brickset.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we did was parse the entire page. Then we looked in that entire page (the variable _soup_) for the div with class name \"content\". Whatever was in there was stored in \"results\".\n",
    "\n",
    "Next up was finding all the anchor-tags that had a href-property. These were fetched in links and reordered in pretty_links as a tuple containing link.text and where it was pointing. Printing the first five shows that the text is the name of the theme and the link text is the name of the page. (We also need to remember the base URL, since it's not in the href-property.)\n",
    "\n",
    "Do note: in the pretty_links-list we don't only have links to every theme, but also to every year. Every minifig in a theme is also in a year, and visa versa. We don't need to download every minifig image twice! First on the agenda is filtering out all non-theme items in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "print(len(pretty_links))\n",
    "\n",
    "r = re.compile(r\"\\d{4}\")\n",
    "\n",
    "filtered_list =  [ data for data in pretty_links if not r.match(data[0])]\n",
    "\n",
    "print(len(filtered_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot going on there:\n",
    "- Compiled regular expression, as we're using it often. (Faster this way.)\n",
    "- Shorthand for, containing a shorthand if (because we have a list of tuples, not of strings. It would have been easier with a list of strings.)\n",
    "\n",
    "Next we'll be doing something different than before: in stead of simply putting a URL in a variable and using that, we'll write a function taking the URL as parameter. This way it's easier to reuse this function later on (as, remember, we have a list of categories). The downside of this when using a Jupyter notebook is if the function is in codeblock A and you call it in codeblock B, then running codeblock B *won't* recompile the function. You'll run the function as it was the last time you ran codeblock A.\n",
    "\n",
    "And what does this function do? We'll be looking at the following pages:\n",
    "\n",
    "![](images/2022-03-08-16-09-11.png)\n",
    "\n",
    "As you can see the interesting part is in the section ```<section class=\"setlist minifiglist\">```. After extracting that we look for all individual images that are conveniently grouped in articles with class \"set\":\n",
    "\n",
    "![](images/2022-03-08-16-17-53.png)\n",
    "\n",
    "We'll extract those and store the information in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://images.brickset.com/minifigs/large/adv001.jpg', 'adv001: Achu'), ('https://images.brickset.com/minifigs/large/adv002.jpg', 'adv002: Alexis Sanister'), ('https://images.brickset.com/minifigs/large/adv027.jpg', 'adv027: Babloo'), ('https://images.brickset.com/minifigs/large/adv004.jpg', 'adv004: Baron Von Barron with Brown Aviator Cap'), ('https://images.brickset.com/minifigs/large/adv005.jpg', 'adv005: Baron Von Barron with Light Gray Aviator Cap'), ('https://images.brickset.com/minifigs/large/adv003.jpg', 'adv003: Baron Von Barron with Pith Helmet'), ('https://images.brickset.com/minifigs/large/adv039.jpg', 'adv039: Baron Von Barron with Pith Helmet and White Epaulettes'), ('https://images.brickset.com/minifigs/large/adv006.jpg', 'adv006: Dr. Charles Lightning'), ('https://images.brickset.com/minifigs/large/adv040.jpg', 'adv040: Dr. Charles Lightning with Backpack'), ('https://images.brickset.com/minifigs/large/adv033.jpg', 'adv033: Dr. Kilroy - Gray Suit')]\n"
     ]
    }
   ],
   "source": [
    "def download_page(url):\n",
    "    page = requests.get(url)\n",
    "    information = []\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find(\"section\", {\"class\": \"setlist minifiglist\"})\n",
    "    # print(results.prettify())\n",
    "    image_list = []\n",
    "\n",
    "    articles = results.find_all(\"article\", {\"class\": \"set\"})\n",
    "\n",
    "    for article in articles:\n",
    "        image = article.find(\"img\", src=True)\n",
    "        image_list.append( ( image[\"src\"], image[\"title\"] ) )\n",
    "        \n",
    "    return image_list\n",
    "\n",
    "images = download_page(\"https://brickset.com/minifigs/category-Adventurers\")\n",
    "print(images[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That much is working. But it hurts: there is a lot more information between those article-tags. Your first assignment will be to get as much information as you can and add it to the dictionary.\n",
    "\n",
    "Also, there's another problem:\n",
    "\n",
    "![](images/2022-03-08-16-32-19.png)\n",
    "\n",
    "Pagination. We're not looking at all minifigs, but only the ones that fitted on the page. There are two solutions:\n",
    "\n",
    "- Do some extra scraping, and get a list of all pages, calling the function on all these pages\n",
    "- Make the existing function recursive: if there is a \"next page\" link, get the list from that page and add it to the returned list.\n",
    "\n",
    "The second is the topic of the first chapter of the AI-course you'll be getting. Let's do a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "def download_page_recursive(url):\n",
    "    page = requests.get(url)\n",
    "    information = []\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find(\"section\", {\"class\": \"setlist minifiglist\"})\n",
    "    # print(results.prettify())\n",
    "    image_list = []\n",
    "\n",
    "    articles = results.find_all(\"article\", {\"class\": \"set\"})\n",
    "\n",
    "    for article in articles:\n",
    "        image = article.find(\"img\", src=True)\n",
    "        image_list.append( ( image[\"src\"], image[\"title\"] ) )\n",
    "\n",
    "    # the new part:\n",
    "    results = soup.find(\"li\", {\"class\": \"next\"}) # look in the entire page, not just the center part\n",
    "    if results != None:\n",
    "        link = results.find(\"a\", href=True)\n",
    "        if link != None:\n",
    "            image_list += download_page(link['href']) # add all returned links to the list we already had\n",
    "        \n",
    "    return image_list\n",
    "\n",
    "images = download_page(\"https://brickset.com/minifigs/category-Adventurers\")\n",
    "print(len(images))\n",
    "\n",
    "images = download_page_recursive(\"https://brickset.com/minifigs/category-Adventurers\")\n",
    "print(len(images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five more, which checks out, because there are five minifigs on the second page. But what, so I hear you think, happens if there is a third page? Well, the second page will have a \"Next\" link as well, so the second page will ask the third page for a list, add that list to the list the second page made and return it to the function creating the list of the first page. And a fourth page? Let the third page handle that. Do note that this only works when the last page doesn't have a \"Next\"-link. If the last page were to have a link to the first page (circular pagination, so to speak) we'd have ourselves an infinite loop.\n",
    "\n",
    "Recursion is complicated, but it does great things. Just watch [this](https://www.youtube.com/watch?v=G_UYXzGuqvM) video. It won't, however, be in the exam for this course.\n",
    "\n",
    "Next up is running this list on all the links we created earlier (the variable pretty_links). Do remember to add the category (the name of the starting-link) to the created list. This is very important information if you want to use the minifig-images later on to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Adventurers', 'https://images.brickset.com/minifigs/large/adv001.jpg', 'adv001: Achu'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv002.jpg', 'adv002: Alexis Sanister'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv027.jpg', 'adv027: Babloo'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv004.jpg', 'adv004: Baron Von Barron with Brown Aviator Cap'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv005.jpg', 'adv005: Baron Von Barron with Light Gray Aviator Cap'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv003.jpg', 'adv003: Baron Von Barron with Pith Helmet'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv039.jpg', 'adv039: Baron Von Barron with Pith Helmet and White Epaulettes'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv006.jpg', 'adv006: Dr. Charles Lightning'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv040.jpg', 'adv040: Dr. Charles Lightning with Backpack'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv033.jpg', 'adv033: Dr. Kilroy - Gray Suit')]\n",
      "[('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp022.png', 'alp022: Ogel Minion, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp033.png', 'alp033: Ogel Minion, Super Ice Drone, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp008.png', 'alp008: Ogel, Black Hands'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp029.png', 'alp029: Ogel, Trans-Medium Blue Hook'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp020.png', 'alp020: Ogel, Trans-Red Hook'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp009.png', 'alp009: Radia'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp012.png', 'alp012: Radia'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp028.png', 'alp028: Radia, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp007.png', 'alp007: Tee Vee'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp030.png', 'alp030: Zed')]\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "for pretty_link in pretty_links[0:3]:\n",
    "    images = download_page_recursive(base_url + pretty_link[1])\n",
    "    all_images += [ (pretty_link[0], im[0], im[1]) for im in images]\n",
    "\n",
    "print(all_images[:10])\n",
    "print(all_images[-10:])\n",
    "print(len(all_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you note the \"[0:3]\" at the end of the for-loop? That is there for testing purposes. A loop like this never works on the first try and this way you can test it without always running it on the full list of a couple of thousand images. And we left it here because for this example the 119 links we have are plenty. There is no need to run all categories and download a list of 13.000 links...\n",
    "\n",
    "So now we have the list. Maybe we want it in a CSV-file? That would be a good way of storing it for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = ['Category', 'URL', 'name']\n",
    "\n",
    "with open('to_download.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do in the Jupyter notebook where we're downloading the images is read the csv (using CSV-writer) and recreate the exact same list-variable we had before. Which seems like a waste, isn't there a way to store the variable as a file and simply re-import the file everytime we need the file? Like we do with vegetables: we put them in a jar with a mixture of salt and vinegar to keep them until the dark days in winter when we need a homemade Bicky-burger with a homemade pickle.\n",
    "\n",
    "(The key word here is [pickle](https://docs.python.org/3/library/pickle.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump( all_images, open( \"all_images.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening a jar with condiments can be very hard. Is the same true for opening a pickle-file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Adventurers', 'https://images.brickset.com/minifigs/large/adv001.jpg', 'adv001: Achu'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv002.jpg', 'adv002: Alexis Sanister'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv027.jpg', 'adv027: Babloo'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv004.jpg', 'adv004: Baron Von Barron with Brown Aviator Cap'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv005.jpg', 'adv005: Baron Von Barron with Light Gray Aviator Cap'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv003.jpg', 'adv003: Baron Von Barron with Pith Helmet'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv039.jpg', 'adv039: Baron Von Barron with Pith Helmet and White Epaulettes'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv006.jpg', 'adv006: Dr. Charles Lightning'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv040.jpg', 'adv040: Dr. Charles Lightning with Backpack'), ('Adventurers', 'https://images.brickset.com/minifigs/large/adv033.jpg', 'adv033: Dr. Kilroy - Gray Suit')]\n",
      "[('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp022.png', 'alp022: Ogel Minion, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp033.png', 'alp033: Ogel Minion, Super Ice Drone, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp008.png', 'alp008: Ogel, Black Hands'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp029.png', 'alp029: Ogel, Trans-Medium Blue Hook'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp020.png', 'alp020: Ogel, Trans-Red Hook'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp009.png', 'alp009: Radia'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp012.png', 'alp012: Radia'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp028.png', 'alp028: Radia, Alpha Team Arctic'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp007.png', 'alp007: Tee Vee'), ('Alpha Team', 'https://img.bricklink.com/ItemImage/MN/0/alp030.png', 'alp030: Zed')]\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "my_images = pickle.load( open( \"all_images.p\", \"rb\" ) )\n",
    "\n",
    "print(my_images[:10])\n",
    "print(my_images[-10:])\n",
    "print(len(my_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e31c2e8d3ed3a4908bbc2c2b66173ad7e7558239e8d6f52669fbf04aeb9634e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
